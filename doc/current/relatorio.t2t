Relatório Final de Andamento do TG1 @nl Localização de Texto em Imagem
Laerte Alves de Almeida Junior GRR20042353 @nl Rafael Charan GRR20053297
%%date(%d/%m/%Y)

%!postproc(html): '<IMG' '<IMG WIDTH=30% HEIGHT=45%'
%!postproc(tex): 'includegraphics([a-zA-Z0-9/}{.]+)@(\d+)x(\d+)' 'includegraphics[width=\2cm,height=\3cm]\1'
%!postproc(tex): 'includegraphics([a-zA-Z0-9/}{.]+)@' 'includegraphics[width=7cm,height=5cm]\1'
%!postproc(html): @nl "<br>"
%!postproc(tex): @nl '\\\\'
%!postproc(tex): @np '\\newpage'
%!postproc: @np ''
%!style(tex): babel
%!postproc(tex): '{babel}' '[brazil]{babel}'
%!postproc(tex): 'documentclass\[(.+)\]\{article\}' 'documentclass[\1]{article}'
%!postproc(tex): '\\clearpage' '%\\clearpage'
%!postproc(tex): 'begin{verbatim}' 'begin{Verbatim}[fontsize=\small]'
%!postproc(tex): 'end{verbatim}' 'end{Verbatim}'
%!postproc(tex): 'amsfonts,graphicx' 'amsfonts,graphicx,fancyvrb'
%!postproc(tex): '@BIB ([a-zA-Z0-9]+)' '\\bibliographystyle{plain}\n\\bibliography{\1}'
%!postproc(tex): '@([a-zA-Z0-9]+)' '\\cite{\1}'
%!postproc(tex): 'GRAUS ([0-9]+) ' '$\1\,^{\\circ}{\\rm C}$'
%!encoding: utf-8


=Introdução=
A indexação de imagens por conteúdo, refere-se à colocação de títulos em imagens, baseando-se no seu conteúdo. Segundo @surveyJain, esse conteúdo pode ser dividido em duas categorias distintas: o conteúdo //perceptível// e o conteúdo //semântico//.

O conteúdo //perceptível// é aquele definido pelos atributos da imagem, como cores, intensidade, forma, texturas, etc. Já o conteúdo semântico é definido pelos objetos, eventos e suas relações nas imagens/vídeos.

O conteúdo //semântico// pode ser definido por texto, faces, veículos ou ações humanas, sendo o texto de grande importância. Isto porque, o texto presente na imagem é muito útil para descrever o seu conteúdo e mais que isso, pode ser facilmente caracterizado e extraído da imagem. Com base no texto ainda, podemos montar interessantes aplicações como buscas de imagens baseadas em palavras chaves, log automático de vídeos e indexação das imagens baseadas no texto.


A nossa aplicação se enquadra neste escopo, de classificação das imagens pelo seu conteúdo semântico. No caso do nosso algoritmo, podemos dizer que estamos buscando uma **classe** do conteúdo semântico das imagens, já que procuramos texto para então classificar as imagens por esse conteúdo (texto).

=Contextualização=

==O texto nas imagens==

Uma grande variadade de abordagens podem ser usadas para extração de texto das imagens. Várias foram propostas como por exemplo, a segmentação de páginas@formatoPalavra, localização de blocos de endereço em fotos@endereco, localização de placas de carros@placas e @placaNeural, e a indexação propriamente dita de imagens e vídeos@videoIndex.

% Nesse paragrafo podia entrar algumas citações para exemplificar esses metodos e suas abordagens especificas

 	Durante a leitura das referencias percebeu-se que a grande maioria dos trabalhos nesta área, sempre foca-se em apenas um tipo específico de texto a ser reconhecido. Isto porque, é sabido que apesar de muitos estudos na área, a grande variedade de possibilidades de tamanho de fontes, estilos, cores, orientação, além das variações de fundos complexos ou com pouco contraste, impossibilitam a construção de um algoritmo eficiente para extração de textos de diferentes formatos das imagens. Em @surveyJain, é comentado alguns desses metodos existentes hoje, os seus acertos e falhas, e melhor exemplifica essas caracteristicas em comum que os metodos focam.

==Análise de layout==

% Citar exemplos que utilizam as abordagens

Uma abordagem eficiente para o reconhecimento de texto em imagens de documentos, revistas e periódicos, é a análise do layout do documento, e a segmentação baseada no forte contraste que normalmente está presente, já que documentos dificilmente terão fundos complexos a serem tratados. Já para imagens coloridas, a abordagem não se torna muito eficiente@colorComplex.

==Métodos baseados na região==

Os métodos baseados em região, usam as propriedades das cores ou escala em preto e branco das regiões de texto, e a relação destas propriedades com as propriedades de cor do fundo da imagem. Existem duas abordagens possíveis sob este tipo de método, a baseada em componentes conexas e as baseadas nos limiares do texto.

Normalmente estas abordagens trabalham a partir de estruturas pequenas, como as componentes conexas ou limiares encontrados, para então, uní-las e dessa combinação montar os retângulos que delimitam as regiões de imagem.

==Métodos baseados em Componentes Conexas==
Estes métodos trabalham, como já citado anteriormente, agrupando pequenas componentes conexas em refinamentos sucessivos, até identificar todas as regiões presentes na imagem. São usados algoritmos de geometria computacional para uní-las de maneira correta e se possível já filtrar aquelas que não representam regiões de texto. Alguns exemplos podem ser encontrados em @avaliacaoMetodosEspanha e @engenharia

==Métodos baseados no contorno/limiar do texto==
  Entre as várias características das regiões de texto dentro de uma imagem, os métodos baseados no contorno, utilizam-se do grande contraste normalmente presente entre a cor do texto e a cor do fundo da imagem. Os contornos da região de texto são identificados e então, dadas essas estruturas que são por exemplo intervalos de pixels, estes intervalos são então unidos e formam então um retângulo (bounded box) que delimita a região de texto. Após isso, vários métodos podem ser usados para que sejam filtradas as regiões que não são de texto propriamente (falsos alarmes). Em @avaliacaoMetodosEspanha, esta abordagem é utilizada.

==Métodos baseados em análise de textura==
Estes métodos, aproveitam-se do fato que o texto presente nas imagens, tem propriedades de textura que são suficientes para distinguí-lo do fundo. Podem ser aplicados filtros, Wavelet, transformada de Fourier, variação espacial para que sejam detectadas as propriedades texturais de uma região de texto na imagem. 
@placaNeural e @colorComplex fazem uso dessas propriedades.

==Outras abordagens==

Existem ainda métodos mais simples para o reconhecimento de texto, como por exemplo, a binarização da imagem utilizando restrições pré-definidas. Estes são métodos de implementação muito simples@formatoPalavra, que normalmente são úteis para o reconhecimento de documentos e outras imagens simples que contém texto, normalmente com fundo branco e texto em preto, tornando fácil o seu reconhecimento. A grande vantagem desse tipo de abordagem é a simplicidade de implementação e o alto desempenho, no que se diz respeito ao custo de tempo que leva a análise.

==Classificação das regiões de texto==

Como explicado em @surveyJain os pesquisadores geralmente classificam as regiões de texto presentes dentro de uma imagem, em dois conjuntos distintos: o conjunto de **textos gráficos** (graphics text) para o texto presente originalmente na figura, e o conjunto de **textos artificiais** (artificial/superimposed text) para os textos de legendas.

Dadas as características, é sabido que o texto gráfico, presente originalmente na imagem, é mais complicado de ser detectado. Isso porque este texto normalmente é influenciado por uma série de fatores, como por exemplo, este texto pode ser distorcido em função da orientação em que foi captada a imagem, e além do mais, pode sofrer muitas variações em função da iluminação, foco e movimentação da imagem.

@np

=Implementação do algoritmo=


==Considerações==
Para o reconhecimento de regiões da imagem que são consideradas texto, assumimos que estas regiões contém muita variação de cor nos pixels. Isso porque nas regiões de transição entre o fundo da imagem e a fonte do texto, há uma diferença de cores bastante acentuada dada a borda das letras.

A avaliação de similaridade/transição de cores dos pixels, é feita a partir de uma constante fornecida para o algoritmo, que é o quanto a cor de um pixel pode variar de outro, sendo que os dois ainda são considerados similares.

Baseando-se nessa idéia, o algoritmo procura o primeiro pixel da linha, que é destoante dos pixels lidos até então (possivelmente, de fundo).

==Intervalos de Variância==

De posse da posição desse pixel, é feita uma leitura dos pixels adiante, buscando a similaridade deles com a do pixel anteriormente encontrado. Essa leitura, é feita dentro de um limite máximo de pixels à frente, estipulado manualmente. Se a região adiante atingir o limite máximo de homogeneidade, ela será descartada, pois não há variação significativa.

Se a região à frente não atingir o limite máximo, e continuar variando com regiões de cores homogêneas ainda menores que o limite, a leitura prosseguirá até que haja uma região que passe do limite, ou que seja atingido o limite de largura da imagem.

Para delimitar o intervalo com variação significativa, é guardada a última posição com pixels discrepantes, na leitura de uma região que ainda não atingiu o limite de homogeneidade.	Depois de feita a leitura de cada linha da imagem, são guardados os intervalos significativos de pixels, em estruturas próprias que contém as coordenadas x e y (início e fim).

==Determinação das Regiões de Texto==
Dados os intervalos encontrados pelo algoritmo, é aplicado um algoritmo de geometria computacional que é encarregado de fazer a união desses intervalos, a fim de formar uma região retangular que delimita a região que é considerada como região de texto da imagem.

Essa união é feita com uma estrutura temporária, que guarda os retângulos até então válidos. De começo, esses retângulos nada mais são do que as regiões da primeira linha onde foi encontrado algum intervalo válido.

Passada a primeira linha, serão avaliados os intervalos da linha seguinte para descobrirmos se há concomitância entre eles. Se houver, serão assumidas as coordenadas horizontais do intervalo maior e as coordenadas verticais do rodapé, serão as do último intervalo lido (pois a leitura é feita de cima para baixo na imagem). Sendo assim, as coordenadas verticais do cabeçalho do retângulo serão sempre as do primeiro intervalo lido que possui concomitância com outros.

Assim por diante, serão analisadas as próximas linhas, sempre comparando-as com os retângulos existentes até então na estrutura temporária.

A distância vertical máxima, entre as coordenadas do rodapé dos retângulos até então construídos, e o intervalo que está sendo lido no momento, para que este seja considerado concomitante (além da avaliação horizontal) é definida também por uma constante informada ao algoritmo.

Como conseqüência do teste de concomitância, o algoritmo também une retângulos que estão em uma mesma linha horizontal, mas com distância muito grande entre si (maior que a constante de homogeneidade definida no algoritmo), se houver um intervalo logo abaixo dessa linha que é concomitante com os dois (ou mais) intervalos logo acima.

Isso é bastante interessante para o caso de, na varredura das primeiras linhas, só sejam encontradas pequenas regiões com variações significativas, como por exemplo, na frase "teste inteligente". Nas primeiras linhas de varredura, só serão encontrados os pingos da letra "i" e a parte de cima das letras "t" e "l", que mesmo estando com uma grande distância entre si, não deixam de fazer parte da mesma região.

Quando a união dos intervalos prosseguir para as linhas abaixo, será encontrado algum intervalo concomitante com todas as pequenas regiões definidas pelas linhas acima, que corresponde a parte central das letras, onde se encontra um intervalo de maior variancia.


==Resultados==

Dessa maneira, ao término do algoritmo, estaremos de posse das regiões onde possivelmente há texto, delimitadas pelos retângulos construídos anteriormente.

Seguem abaixo duas imagens resultantes da aplicação do nosso programa com os parametros //homogeneidade:5,similaridade:10 e distancia vertical:5//.

[imagens/jinnaiConstanteIncorretaWindowsv5l10s15.jpg]@14x10

[imagens/resultadoWindowsInicialv5l10s15.jpg]@14x10

@np

=Evoluções=

=Refinamento do algoritmo de localização de intervalos=

Baseando-se no feedback obtido com os testes realizados com a nossa base de imagens de testes, na implementação anterior do algoritmo, buscou-se refinar a busca de intervalos válidos, afim de implementar uma heurística que assume que numa região de texto a cor (do texto) é única.

Partindo-se desse princípio, o algoritmo de localização de intervalos, foi modificado para que após lida uma região homogênea na cor do texto (menor que a constante de homogeneidade, portanto válida), a próxima região só seja considerada como parte do intervalo, se os pixels que tem cores discrepantes do fundo, também tem cor similar à cor dos pixels encontrados no primeiro intervalo válido da linha.

Dessa maneira, não serão mais consideradas regiões da imagem com muita variação, mas onde a variação não faz sentido. Por exemplo, numa fotografia de uma nuvem, haverá muita variação próximo as bordas dessa nuvem, que poderia anteriormente ser considerada como texto (pois provavelmente não haverá região homogênea maior que o limite), mas que não faz sentido algum dentro da nossa busca.

Para refinar o algoritmo, precisamos apenas de mais uma variável para guardar a cor do primeiro intervalo válido e mais uma variável de controle que diz se o próximo intervalo interessa ou não. Dada a varredura do intervalo, após a primeira faixa de pixels homogêneos na cor do texto, teremos um próximo pixel de cor discrepante que assumimos pertencer ao fundo da imagem. Nesse ponto, nossa variável de controle diz que o intervalo à seguir não é válido, pois última cor lida é discrepante.

Continuando a leitura dos pixels adiante e considerando que eles são homogêneos, porém não da cor que interessa, se for encontrada um pixel de cor diferente após esse intervalo homogêneo, este último intervalo lido não será considerado válido, pois marcamos na variável de controle que o próximo intervalo lido não seria válido. Suponha que a cor do pixel discrepante da região homogênea não válida, é igual a cor dos pixels encontrados no intervalo válido anterior. Se isto acontecer, a variável de controle será setada para considerar o próximo intervalo como válido.

Ou seja, no próximo intervalo de cor homogênea lido, onde esta cor é a cor que interessa, quando houver um pixel de cor discrepante que determina o fim desse intervalo, ele será considerado como válido e a variável setada para que o próximo intervalo não seja válido (pois agora a cor discrepante não é similar a cor que nos interessa).

Se após a leitura do primeiro intervalo homogêneo não válido (após o primeiro válido), for encontrado um pixel de cor discrepante da cor desse intervalo, mas que também não é igual a cor do intervalo inicial, a leitura prosseguirá, mas com a variável de controle marcada de maneira que o próximo intervalo de cor homogênea não será considerado como válido.

Desse modo, a leitura prossegue até o fim da imagem, ou até que seja atingida a constante de homogeneidade como acontecia antes, porém apenas considerando os intervalos que tem cor parecida ao primeiro encontrado.

Este refinamento do algoritmo, foi muito importante para conseguir discernir regiões que contém pequenas imagens aninhadas a posição vertical do texto, que acabavam sendo consideradas como partes do texto também.

Não só as imagens aninhadas à texto, mas também as regiões que contém muita variação com cores não parecidas passaram a ser descartadas após essas modificações, como exemplo, as bordas de nuvens já citadas anteriormente, ícones de uma área de trabalho, ou qualquer tipo de objeto de cor não homogênea e discrepante ao fundo que poderia errôneamente ser considerado como região de texto.


=Problemas encontrados nos resultados até então=

Após o refinamento, o algoritmo mostrou-se bastante eficiente para selecionar o texto das mais variadas imagens, até mesmo com fundo complexo. O problema é que dadas as variações de fonte presentes no texto, o algoritmo fica dependente de constantes que delimitam as regiões a serem buscadas.

São essas as constantes de similaridade, de homogeneidade, de distância vertical máxima e por último, a de tamanho mínimo de regiões válidas.

A primeira constante, não tão problemática até esse ponto, determina a diferença máxima aceitável entre dois pixels para que estes sejam considerados de cor semelhante. Ou seja, é o valor que o algoritmo utiliza, para diferenciar o possível texto do fundo da imagem. O problema é que dadas as diferentes imagens que o algoritmo pode analisar, não é interessante que a comparação seja baseada em um valor fixo, visto que as cores de fundo e texto podem variar, de maneira que alguma região de texto passe despercebida (seja considerada como uma região que faz parte do fundo).

A segunda constante citada (homogeneidade) representa até o momento, o maior empecilho para o funcionamento genérico do algoritmo. Ou seja, até então, é necessário que essa constante seja configurada manualmente para cada imagem analisada, de maneira correta para que seja obtida a melhor seleção das regiões de texto. Isso porque, esse é o valor utilizado para determinar quais intervalos de pixels dentro da varredura de cada linha são variantes o suficiente para serem considerados como válidos (variancia é o parâmetro para a busca).

 Em outras palavras, essa constante está ligada diretamente ao tamanho da fonte contido na imagem analisada. Sendo assim, a dificuldade até então, é justamente determinar esse valor de maneira automática. Vale lembrar, que dado o funcionamento da busca (que procura regiões variantes em pixels, mas de cor homogênea), se a constate encontrada for compatível com a maior fonte do texto, as regiões com fontes pequenas ainda serão encontradas corretamente. A recíproca não é verdadeira, pois o algoritmo não encontra regiões com fontes grandes, se a constante estiver com um valor muito pequeno.

Para tentar solucionar este problema, foi investido algum tempo nas últimas reuniões da equipe, fazendo alguns cálculos de média de tamanho dos intervalos obtidos e também da mediana do tamanho dos intervalos obtidos.

Ou seja, em um primeiro momento, a idéia foi começar com um valor fixo na constante, razoavelmente grande, que seria então estabilizado de acordo com as características da imagem, fazendo-se os cálculos acima citados, a cada novo intervalo válido encontrado.

No cálculo da média, o cálculo sempre tendeu a 1 (1 pixel de tamanho do intervalo), pois era muito influenciado por pequenas regiões encontradas muitas vezes na imagem. A mediana, da mesma maneira não ficou precisa, pois apesar de ter um valor maior, ainda não era suficiente para cobrir todos os casos.

Sendo assim, neste momento, compreendemos que o foco principal é encontrar uma maneira para determinar o valor dessa constante, porém precisamos de mais base teórica ou idéias mais fundamentadas a esse respeito. Pois finalizada essa parte, o algoritmo se tornará muito mais poderoso e eficiente.

Sobre a constante de distância vertical máxima (utilizada na união vertical de intervalos em linhas diferentes), entendemos que existe uma relação muito forte com a constante de homogeneidade, pois o tamanho vertical de fontes, normalmente possui alguma relação de proporcionalidade com a largura.

Já a constante de tamanho mínimo de regiões válidas (no momento, definida diretamente no código), possivelmente também possui alguma relação com a de homogeneidade, no sentido de que devemos desprezar apenas as variações que são pequenas demais para serem algum tipo de fonte, mas não as fontes pequenas em relação a maior presente na imagem. Ou seja, temos idéia de que essa análise deve levar em conta a localidade desse intervalo e os demais que foram encontrados na sua proximidades.

Segue abaixo as imagens resultantes após as nossas melhorias, sendo a primeira imagem com a constante de //homogeneidade:12// e a outra com //homogeneidade:5//. Os demais valores de constantes para ambas imagens seguem os mesmos.

[imagens/jinnaiConstanteCorretav12l10s15.jpg]@14x10

[imagens/resultadoWindowsAposMelhoriav5l10s15.jpg]@14x10

=Solução para o "problema" das constantes: delimitação do escopo de trabalho=

Após algumas reuniões com o orientador, foi definido pela equipe que o mais correto seria delimitar o escopo de trabalho do algoritmo. Com alguma pesquisa e leitura acerca do assunto (outros artigos e trabalhos já feitos) ficou claro que o problema da detecção automática dos mais variados tipos de texto, formas e tamanhos de fonte, é muito complexo de ser resolvido. Normalmente os outros trabalhos encontrados focam-se a solucionar apenas um tipo de problema, ou seja, um tipo de imagem a ser tratada, com suas determinadas características, modelo e tamanho de fonte.

Sendo assim, decidimos delimitar o escopo de trabalho do nosso algoritmo, para a detecção de textos artificiais, sobrepostos, em imagens captadas de sequencias de tv, como filmes, telejornais e outros programas com letras sobrepostas. Nada impede que o algoritmo em algum momento capte também texto natural da imagem, mas vale lembrar que este não será o foco principal.

Delimitando o escopo de detecção, torna-se mais simples encontrar uma combinação das constantes de variância de intervalos e similaridade de pixels, de maneira a otimizar o resultado das regiões encontradas, deixando-as com maior precisão e menos falsos alarmes.

==Regiões importantes sendo desprezadas==

Depois das últimas melhorias, obtivemos bons resultados filtrando grande parte dos falsos alarmes nas imagens reconhecidas e uma significativa melhora na capacidade de discernimento do que é texto ou não, por parte do algoritmo. O grande problema dessa filtragem, é que dadas as características morfológicas das regiões de texto, as quais o nosso algoritmo baseia sua busca, isto acarretou que algumas regiões importantes da imagem fossem descartadas.

Ou seja, apesar de melhorarmos no sentido de que diminuiu o número de regiões de falsos alarmes encontradas, infelizmente este passou também a descartar regiões importantes, que continham texto e informações relevantes, que deveriam ser encontradas.

Na verdade, foi observado pela equipe que normalmente as regiões de falsos alarmes/lixo encontradas pelo algoritmo, consistiam de pequenas regiões com muitas variações de cores. O problema das variações de cores foi resolvido pela abordagem que procura intervalos com variancia apenas de cor semelhante, explicada acima.

Porém, ainda assim pequenas regiões de lixo continuavam a ser encontradas. Dessa maneira, optamos por filtrar regiões menores que uma constante X de pixels, sempre descartando-as. Nesse ponto que regiões com conteúdo importante passaram a ser desprezadas, pois regiões com letras pequenas e/ou com poucas letras isoladas no meio da imagem, passaram a ser desprezadas ou detectadas de maneira falha, como no exemplo abaixo.

%(rodar algoritmo na imagem com_fundo_complexo e colocar constante no meio do pŕograma em 25)
[imagens/imagemcomfundocomplexor25v10l5s35.jpg]@14x10

Até o momento, estávamos descartando todas as regiões encontradas com menos de 25 pixels. Ou seja, regiões com apenas algumas letras disjuntas ou até pequenas palavras, passaram a ser completamente descartadas pelo algoritmo. Diminuindo o valor dessa constante para 10 pixels, obtivemos resultados muito melhores, como pode ser visto no exemplo. Na verdade, o valor dessa constante será fixado em algo entre 5-10 pixels, pois assumiremos que qualquer tipo de texto/informação textual que seja pertinente para o ser humano na imagem, com certeza terá mais de 5 pixels de largura.

Infelizmente, desse modo obviamente o número de falsos alarmes encontrado pelo algoritmo irá aumentar, porém ainda isto ainda é vantajoso, pois é preferível pegarmos todas as regiões importantes com um pouco de falsos alarmes, do que deixar de ter falsos alarmes e acabar por desprezar informações interessantes. Na verdade, os falsos alarmes não são um problema tão sério, considerando que ainda teremos a classificação feita pelo OCR na próxima etapa do algoritmo.

%(rodar algoritmo com a constante menor na mesma imagem citada acima) 
[imagens/imagemcomfundocomplexor10v10l5s35.jpg]@14x10

==Aplicando o algoritmo fazendo varredura de maneira vertical==

Dadas algumas sugestões do orientador e idéias da equipe, decidimos que fazer uma outra varredura na imagem com o mesmo algoritmo após a inicial, só que numa orientação vertical da imagem poderia ser vantajoso no sentido de cobrirmos todos os detalhes das letras no texto.

Isto é, existem alguns pontos que podem falhar no algoritmo, tais como os pingos do i's e quaisquer outras letras que são mais altas que o resto do texto, que provavelmente terão sua parte superior descartada pela constante citada logo acima, de tamanho mínimo dos intervalos que interessam.

Porém, após a diminuição do valor da constante, foi atestado pela equipe que a detecção na maioria dos casos não descarta os pequenos pedaços mais altos, de algumas letras. São raros os casos onde isto aconteceu, não justificando o uso de outra varredura completa, na orientação vertical.

Outra justificativa para se usar uma segunda varredura vertical, é que de posse das regiões encontradas pelas duas varreduras distintas, poderíamos apenas considerar as regiões determinadas pela intersecção de  regiões encontradas na varredura horizontal e regiões encontradas na varredura vertical.

Isto é, partimos do princípio de que se há uma variação válida de texto na orientação horizontal, que indica que este intervalo é uma possível região de texto, também deve haver uma variação na orientação vertical do texto. Ou seja, só interessariam para nós as regiões que possuem variação válida nas duas orientações.

Da mesma maneira, consideramos que possivelmente várias regiões de falsos alarmes encontradas pelo algoritmo passariam a ser descartadas, pois apesar de terem variação na orientação horizontal, provavelmente não teriam variação válida na orientação vertical, de maneira a haver intersecção com a região encontrada na orientação horizontal, já que isto só ocorrerá garantidamente em regiões de texto.

Colocando em prática a idéia e, realizando alguns testes com várias imagens, na verdade constatamos que a grande maioria das regiões de falsos alarmes também possuíam variação suficiente para determinar regiões válidas na orientação vertical.

Ou seja, dessa maneira, já foi invalidada a principal idéia e motivo para se usar a varredura vertical, que seria uma melhor filtragem das regiões de falsos alarmes. Pior que isso, notou-se também que algumas regiões relevantes que continham texto, por vezes não apresentavam variação suficiente para serem consideradas válidas pelo algoritmo na região vertical, já que frases "soltas" de texto por exemplo, não determinam grande variação vertical, como ocorreria em um parágrafo completo. Ou seja, denovo nos deparamos com o problema de descartar regiões importantes, só que dessa vez, sem grandes vantagens na remoção dos falsos alarmes.

==Resultados Obtidos apos implementação com delimitação de escopo==

Segue abaixo algumas imagens já testadas, com grau de similaridade alto, que segue o princípio de nosso escopo (Obter texto artificial).

[imagens/resultadosimg3/img10.jpg]@14x10
[imagens/resultadosimg3/img11.jpg]@14x10
[imagens/resultadosimg3/img2.jpg]@14x10
[imagens/resultadosimg3/img3.jpg]@14x10
[imagens/resultadosimg3/img4.jpg]@14x10
[imagens/resultadosimg3/img5.jpg]@14x10
[imagens/resultadosimg3/img6.jpg]@14x10
[imagens/resultadosimg3/img7.jpg]@14x10
[imagens/resultadosimg3/img9.jpg]@14x10


=Descrição formal do algoritmo atual=

==Diagrama de Fluxo==

%incluir imagem com o diagrama em blocos do algoritmo
[imagens/DiagramaAlgoritmo.jpg]@5x14

@np

==Algoritmo em Pseudo Código==
```
encontre_intervalos;
monte retangulos a partir dos intervalos;

funcao encontre_intervalos () {
para cada linha de imagem_altura {
  intervalo.esquerda é 1;
  enquanto (intervalo.esquerda é menor que imagem.largura) {
    intervalo.esquerda = encontre_primeiro_pixel_discrepante_linha_atual();
    se intervalo.esquerda < imagem.largura {
      intervalo.direita = encontre_ultimo_pixel_intervalo(primeiro_pixel_linha_atual);
      se (intervalo.direita - intervalo.esquerda > 10)
        insere intervalo em lista_intervalos
      intervalo.esquerda é intervalo.direita + 2;
    }
  }
}
}

funcao encontre_ultimo_pixel_intervalo (pixel_atual) {
  repita {
    se são similares o pixel_atual e o pixel anterior no intervalo
      some 1 em pixels_iguais
    senão zera número de pixels_iguais
    se o intervalo interessa
      o ultimo_pixel é o pixel anterior ao atual
    se é similar o primeiro_pixel_intervalo e o pixel atual, 
	próximo intervalo não interessa
    senão o próximo intervalo interessa
    }
    pixel_atual = próximo_pixel;
  } enquanto(pixel_atual é menor que a da largura_imagem e o 
  			número de pixels_iguais é menor que a constante_variancia);
  retorne ultimo_pixel;
}
```

@np

=Aprimoramentos da Solução=


==Nova constate de MOLDURA==

Contante utilizada para aumentar a região do bounded box com um limiar padrão. Esta constante foi utilizada para que o contorno ao redor de todo texto seja obtido com maior precisão, sem precisar de heurísticas muito complicadas que tratam da remoção do lixo sem comprometer a captação das letras.



==Utilização da biblioteca gráfica OpenCV.==

% (ARRUMAR: citar parte onde falamos da tentativa de busca na orientação vertical) 

Em meio as novas implementações sugeridas anteriormente onde iriamos utilizar uma nova busca em orientação vertical visando cruzar informações com a busca horizontal, a fins de diminuir os falsos alarmes e lixos encontrados, nos deparamos com um sério problema vindo da biblioteca de manipulação de imagens. Toda imagem que era rotacionada a GRAUS 90 pelo programa para ser percorrida na orientação vertical (fizemos isso com o propósito de aproveitar o mesmo código da primeira varredura horizontal) acabava por aparecer com uma tarja preta em alguma das colunas de pixels.

Como esta biblioteca foi implementada apenas para fins didáticos da matéria optativa de Processamento de Imagens pelo Laerte, resolvemos optar por uma biblioteca mais robusta e de propósito mais sério que pudesse garantir uma melhor manipulação dos objetos de imagens no trabalho.

Sendo assim decidimos utilizar a biblioteca livre //OpenCV//, pois ela tem capacidade para abrir qualquer formato de arquivo de imagem e transformar num único tipo de objeto que é o IplImage, sendo que antes nosso programa apenas poderia abrir imagens do tipo ppm. Além disso, esta estrutura IplImage fornece uma implementação fornece uma estrutura muito otimizada para a armazenagem da imagem em memória. Enquanto a biblioteca inicial implementava a imagem como uma matriz de ponteiros, onde cada pixel apontava para regiões não contíguas de memória. Essas regiões por sua vez, eram formadas por mais um vetor de ponteiros onde cada um representava um dos canais de cor do pixel. Embora esta implementação funionasse de maneira satisfatória durante todo o desenvolvimento do primeiro trabalho, percebemos que além do problema citado acima, o seu desempenho era terrível devido a tantos ponteiros e alocações necessárias para o funcionamento.

Por outro lado a biblioteca //OpenCV// com a estrutura //IplImage// oferece uma implementação super otimizada, baseada num vetor que armazena todos os pixels da imagem de maneira contígua e acessa cada pixel/componente a partir de um hash simples que determina qual a posição do pixel no vetor. Mais que isso, este hash é bom o suficiente para fazer com que as componentes de cor de cada pixel fiquem lado a lado com as de seus vizinhos na orientação linear do vetor, o que trouxe um expressivo ganho de desempenho na execução das nossas buscas por regiões de texto, já que obrigatoriamente sempre percorremos a imagem na orientação horizontal (cada linha) sequencialmente, linha a linha.

Além disso a //OpenCV// trouxe várias facilidades pelo fato de já encapsular uma infinidade de métodos prontos relacionados à manipulação de imagens. Em especial, os que foram de nosso interesse e ajudaram muito na implementação dos algoritmos, foram os métodos para setar regiões de interesse na imagem principal (//SetImageROI//), já que os textos encontrados dentro da imagem principal nada mais são do que as nossas regiões de interesse dentro desta imagem. Outros métodos que utilizamos bastante foi o método de desenho de retângulos para geração da imagem de saída com os bounded boxes, //CvRetangle// que desenha automaticamente retângulos (antes precisávamos desenhar na mão, com for's encadeados desenhando as linhas de pixels). Também pudemos aproveitar a estrutura já pronta da biblioteca //cvRect// para armazenar os retângulos de texto encontrados no programa.

==Segmentação de texto==

Como um próximo passo no refinamento do nosso algoritmo, decidimos fechar ainda mais o escopo de trabalho para especificamente legendas de vídeos. Baseando-se nesse novo escopo, decidimos após algumas conversas com o orientador que o próximo passo no desenvolvimento será a segmentação das regiões de texto encontradas em regiões de palavras e, posteriormente a segmentação das palavars em caracteres separados, visando uma maior integração e melhoria de resultados na utilização do software de OCR em cima das regiões obtidas.

===Primeiro tópico: Binarização===

Para conseguir detectar de maneira convincente as regiões de palavras dentro da região de texto encontrada pelo programa, pensamos em várias idéias e abordagens diferentes, porém a //melhor// que obtivemos, foi a de binarizar a imagem obtida a fins de separarmos efetivamente o que é texto e o que é fundo dentro da região. Para tanto, esbarramos mais uma vez no problema de como binarizar esta imagem? Que valor utilizar como limiar de binarização? Que relação este valor teria com cada região de texto encontrada?

Em um primeiro momento pensamos que este limiar de binarização poderia se tornar mais uma constante das tantas já presentes no nosso programa, que deveria ser configurada manualmente para a varredura das imagens. Contudo, notamos que este valor era muito difícil de ser definido de maneira genérica tal qual pudesse atender as necessidades dos mais variados tipos de vídeo. O problema é que cada vídeo possui uma característica diferente de texto, principalmente no que se diz respeito à cor da legenda. E justamente, a cor da legenda é fator chave na determinação de um limiar de binarização correto, que descarte todas as variações (ou grande parte delas) de cor do fundo da imagem e deixe bem claro e delineadas as letras do texto.

Uma das opções seria restringir as cores possíveis de legendas que seriam detectáveis pelo nosso algoritmo. Porém, esta alternativa faria com que a nossa abordagem se torna-se muito limitada e pouco aproveitável na prática da fato, visto que não há um padrão de legendas estritamente definido nos variados tipos de vídeos encontrados na internet, muito menos no que se diz respeito à cor.

Paralelamente ao grande problema de definir qual o limiar correto de binarização para ser utilizado, percebemos em alguns testes manuais em editores gráficos com as imagens das regiões de texto obtidas, que dados alguns limiares de valores ajustados arbitrariamente para a binarização, a separação do texto (face da imagem) e do fundo era perfeita. Conseguímos de maneira perfeita deixar todo o texto em cor branca e o fundo quase que completamente preto, com poucas interferências e regiões de lixo.

Tendo testado grupos de imagens com binarizações baseadas em constantes arbitrárias e obtendo os resultados satisfatórios na separação do fundo do texto, percebemos que este realmente seria o caminho a ser seguido. A binarização realmente era o primeiro grande passo na segmentação das regios de texto obtidas.

Voltando um pouco a idéia de como foi implementado o nosso algoritmo para encontrar regiões de texto, que foi explicado no primeiro trabalho, podemos lembrar que as regiões de pixels que são consideradas texto pelo nosso programa, não são regiões com variações aleatórias de cores. Fazendo uma breve explicação do algoritmo, podemos lembrar que ele consistia em pegar o primeiro pixel de cor discrepante (dada a constante de diferença máxima aceitável) e armazená-lo como um possível começo de região de texto. Dado esse pixel de cor discrepante, daqui pra frente sempre vamos procurar por um intervalio de variações que contenha pixels de cor parecida com a do primeiro pixel discrepante em meio a outros pixels com cor de fundo da imagem. Hora, se nosso algoritmo já baseia a sua busca em uma cor específica de interesse, por que não utilizá-la como um possível limiar de binarização ? Pois se temos em mãos intervalos que possuem uma primeira cor discrepante e que após esse primeiro momento, sempre estará se repetindo em meio a outras cores diferentes que são consideradas do fundo da imagem, não é difícil percebermos que esta cor é de fato a cor do texto que está inserido nesta região e foi encontrado pelo algoritmo.

Sendo assim, a cada intervalo de apenas 1 pixel de altura encontrado pelo programa que é considerado como fazendo parte de uma região de texto, guardamos o valor da cor do seu primeiro pixel discrepante (cor de interesse) em uma variável e vamos incrementando um contador do total de intervalos obtidos. Ao término da busca de todos os intervalos, o algoritmo pega a soma de todas as cores de interesse e divide pelo número de intervalos obtidos, chegando assim em uma média da possível cor do texto contido nas regiões obtidas.

De posse dessa média, o que antes parecia um problema muito complicado de ser resolvido, a obtenção do limiar de binarização, tornou-se muito simples. Em um primeiro momento ficou difícil até para a equipe acreditar solução, porém dado o funcionamento do primeiro algoritmo de busca de regiões de texto que já é baseado em buscar regiões de cores uniformes, fica fácil percebermos que é uma solução viável.

Sendo assim, bastou pegarmos esta média calculada das possíveis cores dos textos encontrados e utilizá-la como o famigerado limiar de binarização. E o resultado foi ótimo, dentro do esperado. Para melhorar ainda mais os resultados obtidos, realizamos alguns testes com screenshots variadas de alguns vídeos encontrados na internet utilizando duas abordagens diferentes: em um primeiro momento, determinamos que o limiar de binarização seria obtido a partir da média das três componentes de cor (vermelho, verde e azul). Porém, apesar de obtermos bons resultados, ainda apareciam algumas falhas em imagens que tinham variações de cores mais claras no fundo das imagens de texto, principalmente quando a cor é parecida com a cor do texto.


%colocar exemplos na primeira abordagem, provavelmente será necessário recodificar na maneira antiga, fazendo média.

Em um segundo momento, decidimos que o limiar de binarização seria obtido pelo valor da maior das três componentes de cor da cor de interesse. E esta foi a abordagem que gerou melhores resultados, pois quanto maior o valor do limiar mais lixo é descartado do fundo da imagem e mais nítido e "separado" do fundo fica o texto. Isso porque a média das três componentes acabava por baixar muito o valor do limiar em alguns casos onde uma ou mais componentes da cor tinha valor muito discrepante/baixo, deixando a média próxima também de valores de cores que estão presentes no fundo da imagem e são diferentes da cor do texto.

%colocar exemplo na segunda abordagem.

===Abordagem para dividir palavras dentro das regiões de texto encontradas===

Uma vez que a imagem foi binarizada e agora podemos definir com precisão quais são as regiões de fundo (cor preta) e quais são as regiões de texto (em branco) ficou mais simples dividirmos as regiões de texto encontradas em regiões de palavras separadas. O grande problema deste novo passo, é determinar os espaços pretos que realmente dividem duas letras.

Isto porque, mesmo dentro de uma única letra, podemos ter espaços de fundo intermitentes com as cores de texto sem que esse espaço seja de fato um espaço que separa duas letras. Um exemplo é a letra "o", ou então "a", entre outras que possuem espaços com a cor do fundo dentro da própria região da letra.

%inserir imagem exemplificando letra

===Identificando espaços que estão entre letras===

Para identificar os espaços que estão de fato entre as letras do texto, delimitando-as, precisávamos encontrar uma característica que fosse unicamente deste tipo de espaço e que pudesse garantir que ele não está no meio de algum caracter. Para tanto, após algum tempo tentando encontrar essa característica, observamos que apenas os espaços que nos interessam tem toda a sua extensão vertical na cor do fundo.

Isto é, ao encontrar um pixel qualquer na cor preta dentro da imagem, se toda a extensão vertical da coluna a qual este pixel está inserido é formada por pixels de cor preta, é garantido que esta coluna pertence à um espaço entre duas letras. Sendo assim, basta encontrarmos todas as colunas de pixels que são pretas em toda extensão vertical dentro da região de texto encontrada e então, agrupar aquelas que são vizinhas e formar retângulos que determinam os espaços entre letras.

Dessa maneira, conseguimos identificar com uma certa facilidade todas as regiões de espaços presentes em uma certa região de texto. Porém, só isto ainda não é suficiente para conseguirmos extrair as palavras. Isso porque, as regiões de espaço encontradas podem ser classificadas em dois grupos: os espaços entre letras e os espaço entre palavras. Ou seja, ainda precisamos definir alguma técnica para determinar quais são as regiões que estão entre palavras e não letras.

===Identificando os espaços que estão entre palavras===

Para identificar os espaços que estão entre as palavras dentro da região de texto, iremos trabalhar com uma abordagem onde é feita uma média do tamanho de todos os espaços que estão no meio de dois caracteres. Esta média é feita porque, a partir dela, podemos realizar algumas análises e determinar de maneira razoavelmente precisa quais são os intervalos entre palavras.

Uma das análises definidas, é compararmos o tamanho de cada intervalo com a média obtida. Se este tamanho for igual a média ou ainda, maior que a média, podemos dizer que este é um espaço entre palavras. Isto porque, sabemos que a média é composta do somatório de todos os valores obtidos dividido pelo número de elementos. Sendo assim, é garantido que uma das maneiras de se chegar ao valor da média é que o valor de todos os espaços seja igual ao da média.

Para que tenhamos valores de espaços diferentes daquele obtido na média, para cada espaço menor que esta é garantido que existe um espaço maior e vice-versa, para que a soma total continue sendo igual ao número de elementos multiplicado pelo valor da média. A partir disso, pudemos notar também que os espaços entre as letras sempre são menores que os espaços entre as palavras nas diversas amostras que observamos. Como também é garantido que sempre existirá mais espaços entre letras do que entre palavras, podemos notar que os espaços entre as letras terão mais influência sobre o valor da média do que os espaços entre palavras.

Sendo assim, voltando a observação de que para cada espaço menor que a média deve haver pelo menos um maior que esta para garantir o valor da soma final, podemos deduzir que já que temos muitos valores pequenos de espaços entre letras influenciando a média, os valores de espaços que são iguais ou ainda maiores que a média, são justamente os espaços que estão entre as palavras e são maiores do que aqueles que estão entre letras.

Em resumo temos que aqueles espaços cujo comprimento é maior do que o comprimento médio de espaços, são justamente os espaços que estão situados entre as letras.

%inserir imagem explicativa


=Conclusão=

De uma maneira simples, conseguimos encontrar o nosso objeto de análise (regiões textuais), e tambem nos aproveitando das estruturas existentes para detectar as regiões de possivel texto, conseguimos uma boa aproximação para destacar o fundo da fonte, o que nos possibilitou uma solução simples para a detecção de palavras numa imagem textual. Apesar de ainda ser possivel nos aprofundamos mais neste topico, decidimos que a nossa pesquisa até esse ponto sobre detecção de texto em imagens já de alguma ajuda para este tópico na socidade, onde surgem a cada dia mais aplicações para esta solução.

@BIB referencia
